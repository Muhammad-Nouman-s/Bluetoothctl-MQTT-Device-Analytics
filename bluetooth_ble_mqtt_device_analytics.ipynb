{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95356652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Centralizes filesystem paths, BLE identifier patterns, and other constants\n",
    "used throughout the BLE data processing workflow.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Dataset path (update as needed)\n",
    "DEFAULT_CSV: Path = Path(\"data\") / \"mqtt_input.csv\"\n",
    "\n",
    "# Gateway MAC (update as needed)\n",
    "GATEWAY_MAC: str = \"AA:BB:CC:DD:EE:FF\"\n",
    "GATEWAY_MAC = GATEWAY_MAC.upper()\n",
    "\n",
    "# Shared pattern fragments for constructing BLE-related regular expressions\n",
    "_HEX_DIGITS = r\"[0-9A-Fa-f]\"\n",
    "_HEX_PAIR = rf\"{_HEX_DIGITS}{{2}}\"\n",
    "\n",
    "# Validates standard BLE MAC address formatting (AA:BB:CC:DD:EE:FF)\n",
    "MAC_RE = re.compile(rf\"({_HEX_PAIR}(?::{_HEX_PAIR}){{5}})\")\n",
    "\n",
    "# Matches a 128-bit BLE UUID in the 8-4-4-4-12 hexadecimal structure\n",
    "UUID128_RE = re.compile(\n",
    "    rf\"({_HEX_DIGITS}{{8}}-{_HEX_DIGITS}{{4}}-{_HEX_DIGITS}{{4}}-{_HEX_DIGITS}{{4}}-{_HEX_DIGITS}{{12}})\"\n",
    ")\n",
    "\n",
    "# Provided token represents exactly one hexadecimal byte\n",
    "HEX_BYTE_RE = re.compile(rf\"^{_HEX_PAIR}$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loads MQTT-generated CSV file and parses nested JSON payloads into a structured\n",
    "form for BLE analysis.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def configure_logging(level: int = logging.INFO) -> None:\n",
    "    \"\"\"Configure simple console logging.\"\"\"\n",
    "    root = logging.getLogger()\n",
    "    if root.handlers:\n",
    "        return\n",
    "    logging.basicConfig(level=level, format=\"%(message)s\")\n",
    "\n",
    "\n",
    "def load_csv(file_path: str | Path) -> pd.DataFrame:\n",
    "    \"\"\"Loads the CSV dataset from disk and reports rows/columns.\"\"\"\n",
    "    logger.info(\"Loading CSV: %s\", file_path)\n",
    "    df = pd.read_csv(file_path)\n",
    "    logger.info(\"Loaded %d rows and columns: %s\", len(df), df.columns.tolist())\n",
    "    return df\n",
    "\n",
    "\n",
    "def safe_json_load(text: Any) -> dict:\n",
    "    \"\"\"Parse JSON string safely, return {} on failure.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def parse_payload(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parses each row's JSON payload and extracts:\n",
    "      - log_timestamp\n",
    "      - revelations_raw\n",
    "    \"\"\"\n",
    "    if \"payload\" not in df.columns:\n",
    "        raise KeyError(\"CSV does not contain the required 'payload' column.\")\n",
    "\n",
    "    df = df.copy()\n",
    "    parsed = df[\"payload\"].apply(safe_json_load)\n",
    "    df[\"payload_json\"] = parsed\n",
    "    df[\"log_timestamp\"] = parsed.apply(lambda x: x.get(\"timestamp\"))\n",
    "    df[\"revelations_raw\"] = parsed.apply(lambda x: x.get(\"revelations\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1cf0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging with a simple, message-only format.\n",
    "configure_logging()\n",
    "\n",
    "# Load the dataset and parse BLE-relevant metadata from JSON payloads\n",
    "df = load_csv(DEFAULT_CSV)\n",
    "df = parse_payload(df)\n",
    "\n",
    "# Display sample timestamps from the parsed payload for verification\n",
    "print(df[\"log_timestamp\"].head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525bfd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inspects the raw MQTT metadata prior to processing. The inspection summarizes\n",
    "the structure of the timestamp, topic, and payload columns to ensure that incoming\n",
    "messages follow the expected format before deeper parsing occurs.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def describe_column(label: str, series: pd.Series, sample_size: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Displays the data type, number of unique values, and a small sample for a\n",
    "    specified DataFrame column.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{label}\")\n",
    "    print(\"Type:\", series.dtype)\n",
    "    print(\"Unique values:\", series.nunique())\n",
    "    print(\"\\nSample values:\")\n",
    "    print(series.head(sample_size).to_string(index=False))\n",
    "\n",
    "\n",
    "# Inspect MQTT client's timestamp metadata\n",
    "describe_column(\n",
    "    label=\"TIMESTAMP_CLIENT\",\n",
    "    series=df[\"timestamp_client\"],\n",
    "    sample_size=10\n",
    ")\n",
    "\n",
    "# Inspect MQTT topic metadata\n",
    "print(\"\\nTOPIC column\")\n",
    "print(\"Unique topics:\", df[\"topic\"].nunique())\n",
    "\n",
    "print(\"\\nList of distinct topics:\")\n",
    "for topic_name in df[\"topic\"].unique():\n",
    "    print(\" -\", topic_name)\n",
    "\n",
    "print(\"\\nSample topic values:\")\n",
    "print(df[\"topic\"].head(3).to_string(index=False))\n",
    "\n",
    "# Inspect raw JSON payload structure\n",
    "print(\"\\nPAYLOAD column \")\n",
    "print(\"Showing first five payload entries:\\n\")\n",
    "\n",
    "for idx, value in df[\"payload\"].head(5).items():\n",
    "    print(f\"[PAYLOAD {idx}]\")\n",
    "    print(value)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleans raw BLE scan output by removing ANSI escape sequences and control\n",
    "characters. The cleaned content is stored separately to simplify downstream\n",
    "parsing and analysis.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def clean_ansi(text: Any) -> Any:\n",
    "    \"\"\"\n",
    "    Removes ANSI escape sequences and selected control characters from a\n",
    "    bluetoothctl scan string. Non-string values are returned unchanged.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    cleaned = re.sub(r\"\\x1B\\[[0-?]*[ -/]*[@-~]\", \"\", text)\n",
    "    cleaned = cleaned.replace(\"\\x01\", \"\").replace(\"\\x02\", \"\")\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# ANSI-cleaned BLE scan output\n",
    "df[\"revelations_clean\"] = df[\"revelations_raw\"].apply(clean_ansi)\n",
    "print(\"Derived 'revelations_clean' by stripping ANSI and control codes.\")\n",
    "\n",
    "# Preview a small sample to verify cleaning behavior\n",
    "print(\"\\nREVELATIONS: RAW vs CLEAN \\n\")\n",
    "for idx, row in df[[\"revelations_raw\", \"revelations_clean\"]].head(3).iterrows():\n",
    "    print(f\"Row {idx}\")\n",
    "    print(\"RAW:\")\n",
    "    print(row[\"revelations_raw\"])\n",
    "    print(\"\\nCLEAN:\")\n",
    "    print(row[\"revelations_clean\"])\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb92887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Identifies and counts controller-related state changes detected in cleaned BLE\n",
    "scan output. The results summarise controller behaviour across all MQTT messages.\n",
    "\"\"\"\n",
    "\n",
    "controller_patterns = {\n",
    "    \"[CHG] Controller\": 0,\n",
    "    \"[NEW] Controller\": 0,\n",
    "    \"[DEL] Controller\": 0,\n",
    "    \"Discovering: yes\": 0,\n",
    "    \"Discovering: no\": 0,\n",
    "    \"Powered: yes\": 0,\n",
    "    \"Powered: no\": 0,\n",
    "    \"Pairable: yes\": 0,\n",
    "    \"Pairable: no\": 0,\n",
    "}\n",
    "\n",
    "total_rows = len(df)\n",
    "\n",
    "\n",
    "def controller_event_present(text: Any) -> bool:\n",
    "    \"\"\"\n",
    "    Determines whether a scan string contains one or more controller-related\n",
    "    markers, including state transitions and discovery indicators.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "\n",
    "    if \"Controller \" in text:\n",
    "        return True\n",
    "\n",
    "    for marker in (\"Discovering:\", \"Powered:\", \"Pairable:\"):\n",
    "        if marker in text:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# Reset counters to ensure reproducible results on re-execution\n",
    "for key in controller_patterns:\n",
    "    controller_patterns[key] = 0\n",
    "\n",
    "# Count individual controller state markers across all messages\n",
    "for text in df[\"revelations_clean\"]:\n",
    "    if not isinstance(text, str):\n",
    "        continue\n",
    "\n",
    "    for pattern in controller_patterns:\n",
    "        if pattern in text:\n",
    "            controller_patterns[pattern] += 1\n",
    "\n",
    "# Count how many messages contain any controller-related activity\n",
    "rows_with_controller = sum(\n",
    "    controller_event_present(txt) for txt in df[\"revelations_clean\"]\n",
    ")\n",
    "\n",
    "# Report controller-level summary\n",
    "print(\"\\nCONTROLLER-LEVEL EVENTS\\n\")\n",
    "print(f\"Total MQTT messages: {total_rows}\")\n",
    "print(f\"Messages with controller activity: {rows_with_controller}\\n\")\n",
    "\n",
    "print(\"Controller event counts:\")\n",
    "for pattern, count in controller_patterns.items():\n",
    "    print(f\"  {pattern:<18} -> {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c32d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collects all BLE MAC addresses observed in cleaned scan output, aggregates their\n",
    "occurrences across MQTT messages, and computes device-level statistics.\n",
    "\"\"\"\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def extract_mac_list(block_text: Any) -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns all MAC addresses found in a single cleaned scan block.\n",
    "    Includes both device and gateway MACs; separation is handled downstream.\n",
    "    \"\"\"\n",
    "    if not isinstance(block_text, str):\n",
    "        return []\n",
    "    return [match.upper() for match in MAC_RE.findall(block_text)]\n",
    "\n",
    "\n",
    "# Ensure required input is present\n",
    "if \"revelations_clean\" not in df.columns:\n",
    "    raise KeyError(\n",
    "        \"Expected 'revelations_clean' column not found. Run the cleaning step first.\"\n",
    "    )\n",
    "\n",
    "# Extract MAC lists per message\n",
    "df[\"mac_list\"] = df[\"revelations_clean\"].apply(extract_mac_list)\n",
    "\n",
    "# Flatten MACs across all messages\n",
    "all_macs = [mac for macs in df[\"mac_list\"] if isinstance(macs, list) for mac in macs]\n",
    "unique_macs = sorted(set(all_macs))\n",
    "\n",
    "# Count MAC occurrences\n",
    "mac_event_counts = Counter(all_macs)\n",
    "\n",
    "# Separate gateway from devices\n",
    "gateway_event_count = mac_event_counts.get(GATEWAY_MAC, 0)\n",
    "device_macs = [mac for mac in unique_macs if mac != GATEWAY_MAC]\n",
    "\n",
    "print(\"\\nBLE DEVICE IDENTIFICATION\\n\")\n",
    "print(f\"Distinct MAC addresses observed: {len(unique_macs)}\")\n",
    "print(f\"Distinct devices: {len(device_macs)}\")\n",
    "print(f\"Gateway MAC ({GATEWAY_MAC}) associated with {gateway_event_count} events\\n\")\n",
    "\n",
    "# Show most frequent MACs\n",
    "print(\"MAC event frequencies :\\n\")\n",
    "for mac, count in mac_event_counts.most_common(5):\n",
    "    print(f\"{mac:<18} -> {count} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scans the cleaned bluetoothctl output line by line, finds device-related events \n",
    "([NEW], [CHG], [DEL]), extracts the MAC address from each event, and groups all \n",
    "events belonging to the same device together.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def is_device_event_line(line: str) -> bool:\n",
    "    \"\"\"\n",
    "    Indicates whether a log line represents a device-level event emitted by\n",
    "    bluetoothctl, based on its prefix tag.\n",
    "    \"\"\"\n",
    "    prefixes = (\"[NEW] Device \", \"[CHG] Device \", \"[DEL] Device \")\n",
    "    return any(line.startswith(prefix) for prefix in prefixes)\n",
    "\n",
    "\n",
    "# Ensure required input is present\n",
    "if \"revelations_clean\" not in df.columns:\n",
    "    raise KeyError(\n",
    "        \"Expected 'revelations_clean' column not found.\"\n",
    "    )\n",
    "\n",
    "mac_events_by_device: dict[str, list[str]] = {}\n",
    "\n",
    "for text in df[\"revelations_clean\"]:\n",
    "    if not isinstance(text, str):\n",
    "        continue\n",
    "\n",
    "    for raw_line in text.splitlines():\n",
    "        line = raw_line.strip()\n",
    "        if not is_device_event_line(line):\n",
    "            continue\n",
    "\n",
    "        match = MAC_RE.search(line)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        mac = match.group(1).upper()\n",
    "        if mac == GATEWAY_MAC:\n",
    "            continue  # exclude gateway events\n",
    "\n",
    "        mac_events_by_device.setdefault(mac, []).append(line)\n",
    "\n",
    "print(\"\\nDEVICE EVENTS GROUPED BY MAC \\n\")\n",
    "print(f\"Devices with device-level events: {len(mac_events_by_device)}\")\n",
    "\n",
    "# Show top 5 devices by event count\n",
    "top_devices = sorted(\n",
    "    mac_events_by_device.items(),\n",
    "    key=lambda item: len(item[1]),\n",
    "    reverse=True\n",
    ")[:5]\n",
    "\n",
    "for mac, events in top_devices:\n",
    "    print(f\"MAC: {mac} -> {len(events)} events\")\n",
    "\n",
    "print(\"\\nUse show_device_events_only(<mac>) to inspect full event history for a device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e8690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extracts iBeacon identifiers from cleaned BLE scan output. For each device, the\n",
    "block derives (MAC, UUID, major, minor) tuples, builds a flat table, and reports\n",
    "how many devices have iBeacon data.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def extract_ibeacon_tuples(block_text: Any) -> list[tuple[str, str, int, int]]:\n",
    "    \"\"\"\n",
    "    Returns all iBeacon tuples found in a single cleaned scan block.\n",
    "    Each tuple has the form (mac, beacon_uuid, major_dec, minor_dec).\n",
    "    \"\"\"\n",
    "    results: list[tuple[str, str, int, int]] = []\n",
    "\n",
    "    if not isinstance(block_text, str):\n",
    "        return results\n",
    "\n",
    "    lines = block_text.splitlines()\n",
    "    current_mac: str | None = None\n",
    "    idx = 0\n",
    "\n",
    "    while idx < len(lines):\n",
    "        line = lines[idx].strip()\n",
    "\n",
    "        match = MAC_RE.search(line)\n",
    "        if match:\n",
    "            current_mac = match.group(1).upper()\n",
    "\n",
    "        if \"ManufacturerData Value:\" in line and current_mac is not None:\n",
    "            hex_bytes: list[str] = []\n",
    "            cursor = idx + 1\n",
    "\n",
    "            while cursor < len(lines):\n",
    "                token_line = lines[cursor].strip()\n",
    "                if not token_line:\n",
    "                    break\n",
    "\n",
    "                tokens = token_line.split()\n",
    "                hex_tokens = [\n",
    "                    token for token in tokens if HEX_BYTE_RE.fullmatch(token)\n",
    "                ]\n",
    "                if not hex_tokens:\n",
    "                    break\n",
    "\n",
    "                hex_bytes.extend(hex_tokens)\n",
    "                cursor += 1\n",
    "\n",
    "            if (\n",
    "                len(hex_bytes) >= 23\n",
    "                and hex_bytes[0].lower() == \"02\"\n",
    "                and hex_bytes[1].lower() == \"15\"\n",
    "            ):\n",
    "                uuid_bytes = hex_bytes[2:18]\n",
    "                major_bytes = hex_bytes[18:20]\n",
    "                minor_bytes = hex_bytes[20:22]\n",
    "\n",
    "                beacon_uuid = (\n",
    "                    uuid_bytes[0] + uuid_bytes[1] + uuid_bytes[2] + uuid_bytes[3]\n",
    "                    + \"-\"\n",
    "                    + uuid_bytes[4] + uuid_bytes[5]\n",
    "                    + \"-\"\n",
    "                    + uuid_bytes[6] + uuid_bytes[7]\n",
    "                    + \"-\"\n",
    "                    + uuid_bytes[8] + uuid_bytes[9]\n",
    "                    + \"-\"\n",
    "                    + \"\".join(uuid_bytes[10:])\n",
    "                ).lower()\n",
    "\n",
    "                major_dec = int(major_bytes[0] + major_bytes[1], 16)\n",
    "                minor_dec = int(minor_bytes[0] + minor_bytes[1], 16)\n",
    "\n",
    "                results.append((current_mac, beacon_uuid, major_dec, minor_dec))\n",
    "\n",
    "            idx = cursor\n",
    "        else:\n",
    "            idx += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Extract iBeacon tuples per message\n",
    "df[\"mac_beacon_tuples\"] = df[\"revelations_clean\"].apply(extract_ibeacon_tuples)\n",
    "\n",
    "# Flatten extracted tuples\n",
    "flat_rows: list[tuple[str, str, int, int]] = []\n",
    "for tuples in df[\"mac_beacon_tuples\"]:\n",
    "    if isinstance(tuples, list):\n",
    "        flat_rows.extend(tuples)\n",
    "\n",
    "mac_beacon_df = (\n",
    "    pd.DataFrame(flat_rows, columns=[\"mac\", \"beacon_uuid\", \"major\", \"minor\"])\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Exclude gateway MAC to align with device-level analysis\n",
    "mac_beacon_df = mac_beacon_df[\n",
    "    mac_beacon_df[\"mac\"] != GATEWAY_MAC\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Aggregate to one iBeacon tuple per device\n",
    "if not mac_beacon_df.empty:\n",
    "    mac_beacon_agg = (\n",
    "        mac_beacon_df\n",
    "        .sort_values([\"mac\", \"beacon_uuid\", \"major\", \"minor\"])\n",
    "        .groupby(\"mac\", as_index=False)\n",
    "        .first()\n",
    "    )\n",
    "else:\n",
    "    mac_beacon_agg = pd.DataFrame(\n",
    "        columns=[\"mac\", \"beacon_uuid\", \"major\", \"minor\"]\n",
    "    )\n",
    "\n",
    "print(\"\\niBeacon IDENTIFIERS\\n\")\n",
    "print(f\"Total iBeacon records: {len(mac_beacon_df)}\")\n",
    "print(f\"Devices with iBeacon tuples: {mac_beacon_df['mac'].nunique()}\")\n",
    "print(f\"Unique beacon UUIDs: {mac_beacon_df['beacon_uuid'].nunique()}\\n\")\n",
    "\n",
    "if not mac_beacon_df.empty:\n",
    "    print(\"Sample iBeacon tuples:\")\n",
    "    print(mac_beacon_df.head(10).to_string(index=False))\n",
    "\n",
    "total_devices = len(device_macs)\n",
    "devices_with_tuple = mac_beacon_agg[\"mac\"].nunique()\n",
    "devices_without_tuple = total_devices - devices_with_tuple\n",
    "\n",
    "print(\"\\nDevice coverage summary\\n\")\n",
    "print(f\"Total devices : {total_devices}\")\n",
    "print(f\"Devices exposing (UUID, major, minor): {devices_with_tuple}\")\n",
    "print(f\"Devices without iBeacon tuple: {devices_without_tuple}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95009407",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes each deviceâ€™s presence window (first seen, last seen, duration) using MQTT \n",
    "timestamps and links any available iBeacon identifiers..\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Validate required inputs\n",
    "if \"timestamp_client\" not in df.columns:\n",
    "    raise ValueError(\"Expected 'timestamp_client' column not found in DataFrame.\")\n",
    "if \"mac_list\" not in df.columns:\n",
    "    raise ValueError(\"Expected 'mac_list' column not found in DataFrame.\")\n",
    "\n",
    "# Normalize timestamp column for time-based aggregation\n",
    "df[\"timestamp_client\"] = pd.to_datetime(df[\"timestamp_client\"], errors=\"coerce\")\n",
    "time_column = \"timestamp_client\"\n",
    "\n",
    "# Build a per-observation event table: (mac, timestamp)\n",
    "event_records: list[tuple[str, pd.Timestamp]] = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    macs = row.get(\"mac_list\", [])\n",
    "    ts = row[time_column]\n",
    "\n",
    "    if not isinstance(macs, list) or not macs or pd.isna(ts):\n",
    "        continue\n",
    "\n",
    "    for mac in macs:\n",
    "        event_records.append((mac.upper(), ts))\n",
    "\n",
    "mac_events = pd.DataFrame(event_records, columns=[\"mac\", \"timestamp\"])\n",
    "\n",
    "# Derive first/last sighting times per MAC\n",
    "if mac_events.empty:\n",
    "    mac_spans = pd.DataFrame(columns=[\"mac\", \"enter_time\", \"exit_time\"])\n",
    "else:\n",
    "    mac_spans = (\n",
    "        mac_events\n",
    "        .groupby(\"mac\")\n",
    "        .agg(\n",
    "            enter_time=(\"timestamp\", \"min\"),\n",
    "            exit_time=(\"timestamp\", \"max\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "# Exclude gateway MAC from device presence intervals\n",
    "mac_spans = mac_spans[mac_spans[\"mac\"] != GATEWAY_MAC].reset_index(drop=True)\n",
    "\n",
    "# Attach iBeacon identifiers (if available) and compute presence duration\n",
    "devices_full = (\n",
    "    mac_spans\n",
    "    .merge(mac_beacon_agg, on=\"mac\", how=\"left\")\n",
    "    .sort_values(\"mac\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "devices_full[\"duration_seconds\"] = (\n",
    "    devices_full[\"exit_time\"] - devices_full[\"enter_time\"]\n",
    ").dt.total_seconds()\n",
    "\n",
    "\n",
    "devices_full = devices_full[\n",
    "    [\"mac\", \"enter_time\", \"exit_time\", \"duration_seconds\", \"beacon_uuid\", \"major\", \"minor\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea71c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-device presence with first/last sightings, duration, and iBeacon identifiers.\n",
    "devices_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d0ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(devices_full.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes activity metrics for each BLE device based on its appearance in the\n",
    "per-message event log. For every MAC, the block derives event counts, presence\n",
    "duration, and event rates over various time scales.\n",
    "\"\"\"\n",
    "\n",
    "# Handle empty event table\n",
    "if mac_events.empty:\n",
    "    device_freq_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"mac\",\n",
    "            \"n_events\",\n",
    "            \"duration_seconds\",\n",
    "            \"events_500ms\",\n",
    "            \"events_per_second\",\n",
    "            \"events_per_minute\",\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    # Aggregate event counts and time bounds per MAC\n",
    "    per_mac = (\n",
    "        mac_events\n",
    "        .groupby(\"mac\")\n",
    "        .agg(\n",
    "            n_events=(\"timestamp\", \"size\"),\n",
    "            enter_time=(\"timestamp\", \"min\"),\n",
    "            exit_time=(\"timestamp\", \"max\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Exclude gateway MAC from activity metrics\n",
    "    per_mac = per_mac[per_mac[\"mac\"] != GATEWAY_MAC].reset_index(drop=True)\n",
    "\n",
    "    # Compute presence duration\n",
    "    per_mac[\"duration_seconds\"] = (\n",
    "        per_mac[\"exit_time\"] - per_mac[\"enter_time\"]\n",
    "    ).dt.total_seconds()\n",
    "\n",
    "    # Remove zero-duration rows to avoid division-by-zero\n",
    "    per_mac = per_mac[per_mac[\"duration_seconds\"] > 0].copy()\n",
    "\n",
    "    # Compute event frequency metrics per device\n",
    "    per_mac[\"events_per_second\"] = per_mac[\"n_events\"] / per_mac[\"duration_seconds\"]\n",
    "    per_mac[\"events_per_minute\"] = per_mac[\"events_per_second\"] * 60.0\n",
    "    per_mac[\"events_500ms\"] = per_mac[\"events_per_second\"] * 0.5\n",
    "\n",
    "    # Final, report-ready table\n",
    "    device_freq_df = (\n",
    "        per_mac[\n",
    "            [\n",
    "                \"mac\",\n",
    "                \"n_events\",\n",
    "                \"duration_seconds\",\n",
    "                \"events_500ms\",\n",
    "                \"events_per_second\",\n",
    "                \"events_per_minute\",\n",
    "            ]\n",
    "        ]\n",
    "        .sort_values(\"mac\")\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show as DataFrame \n",
    "device_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb568463",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device_freq_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6080a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_device_events_only(mac: str) -> None:\n",
    "    \"\"\"\n",
    "    Displays bluetoothctl lines involving a single MAC address, based on the\n",
    "    ANSI-cleaned scan text stored in the 'revelations_clean' column.\n",
    "    \"\"\"\n",
    "    if \"revelations_clean\" not in df.columns:\n",
    "        raise KeyError(\"Expected 'revelations_clean' column is missing.\")\n",
    "\n",
    "    mac_norm = mac.upper()\n",
    "    events: list[tuple[int, object, str]] = []\n",
    "\n",
    "    for row in df.itertuples(index=True):\n",
    "        block = getattr(row, \"revelations_clean\", None)\n",
    "        if not isinstance(block, str) or mac_norm not in block:\n",
    "            continue\n",
    "\n",
    "        timestamp = getattr(row, \"timestamp_client\", None)\n",
    "        for line in block.splitlines():\n",
    "            if mac_norm in line:\n",
    "                events.append((row.Index, timestamp, line))\n",
    "\n",
    "    row_count = len({idx for idx, _, _ in events})\n",
    "    line_count = len(events)\n",
    "\n",
    "    print(f\"\\nEvents for device {mac_norm}\")\n",
    "    print(f\"Rows containing this MAC: {row_count}\")\n",
    "    print(f\"Event lines for this MAC: {line_count}\\n\")\n",
    "\n",
    "    for idx, ts, line in events:\n",
    "        print(f\"Row index: {idx}\")\n",
    "        print(\"timestamp_client:\", ts)\n",
    "        print(\"event:\", line)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba9a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_device_events_only(\"AA:BB:CC:DD:EE:FF\") # (Chnage MAC Address)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
